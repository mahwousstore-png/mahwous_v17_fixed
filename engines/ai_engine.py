"""
engines/ai_engine.py v19.0
- Gemini ูุจุงุดุฑ + Grounding (ุจุญุซ ุญูููู)
- fragranticarabia.com โ ุตูุฑ + ููููุงุช ุงูุนุทูุฑ
- Mahwous ูุตู ุฎุงุต ููููุชุฌุงุช ุงูููููุฏุฉ
- ุชุญูู ููุชุฌ | ุจุญุซ ุณูู | ุชุญููู ูุฌูุน | ุฏุฑุฏุดุฉ
"""
import requests, json, re, time
from config import GEMINI_API_KEYS, OPENROUTER_API_KEY, COHERE_API_KEY

_GM  = "gemini-2.0-flash"
_GU  = f"https://generativelanguage.googleapis.com/v1beta/models/{_GM}:generateContent"
_GUS = f"https://generativelanguage.googleapis.com/v1beta/models/{_GM}:streamGenerateContent"
_OR  = "https://openrouter.ai/api/v1/chat/completions"
_CO  = "https://api.cohere.ai/v1/generate"
_FR  = "https://www.fragranticarabia.com"

# โโ System Prompts ูุฎุตุตุฉ ููู ูุณู โโโโโโโโโโโโโโ
PAGE_PROMPTS = {
"price_raise": """ุฃูุช ุฎุจูุฑ ุชุณุนูุฑ ุนุทูุฑ ูุงุฎุฑุฉ (ุงูุณูู ุงูุณุนูุฏู) โ ูุณู ยซุณุนุฑ ุฃุนููยป.
ุณุนุฑูุง ุฃุนูู ูู ุงูููุงูุณ. ููุงุนุฏ: ูุฑู<10 โ ุฅุจูุงุก | 10-30 โ ูุฑุงุฌุนุฉ | >30 โ ุฎูุถ ููุฑู.
ููู ููุชุฌ: 1.ูู ุงููุทุงุจูุฉ ุตุญูุญุฉุ 2.ูู ุงููุฑู ูุจุฑุฑุ 3.ุงูุณุนุฑ ุงูููุชุฑุญ.
ุฃุฌุจ ุจุงูุนุฑุจูุฉ ุจุฅูุฌุงุฒ ูุงุญุชุฑุงููุฉ.""",
"price_lower": """ุฃูุช ุฎุจูุฑ ุชุณุนูุฑ ุนุทูุฑ ูุงุฎุฑุฉ (ุงูุณูู ุงูุณุนูุฏู) โ ูุณู ยซุณุนุฑ ุฃููยป.
ุณุนุฑูุง ุฃูู ูู ุงูููุงูุณ = ูุฑุตุฉ ุฑุจุญ ุถุงุฆุนุฉ. ูุฑู<10 โ ุฅุจูุงุก | 10-50 โ ุฑูุน ุชุฏุฑูุฌู | >50 โ ุฑูุน ููุฑู.
ููู ููุชุฌ: 1.ูู ูููู ุฑูุน ุงูุณุนุฑุ 2.ุงูุณุนุฑ ุงูุฃูุซู. ุฃุฌุจ ุจุงูุนุฑุจูุฉ ุจุฅูุฌุงุฒ.""",
"approved": "ุฃูุช ุฎุจูุฑ ุชุณุนูุฑ ุนุทูุฑ. ุฑุงุฌุน ุงูููุชุฌุงุช ุงูููุงูู ุนูููุง ูุชุฃูุฏ ูู ุงุณุชูุฑุงุฑ ุตูุงุญูุชูุง. ุฃุฌุจ ุจุงูุนุฑุจูุฉ.",
"missing": """ุฃูุช ุฎุจูุฑ ุนุทูุฑ ูุงุฎุฑุฉ โ ูุชุฎุตุต ูู ุงูููุชุฌุงุช ุงูููููุฏุฉ ุจูุชุฌุฑ ููููุณ.
ููู ููุชุฌ: 1.ูู ูู ุญูููู ูููุซููุ 2.ูู ูุณุชุญู ุงูุฅุถุงูุฉุ 3.ุงูุณุนุฑ ุงูููุชุฑุญ. 4.ุฃููููุฉ ุงูุฅุถุงูุฉ (ุนุงููุฉ/ูุชูุณุทุฉ/ููุฎูุถุฉ). ุฃุฌุจ ุจุงูุนุฑุจูุฉ.""",
"review": "ุฃูุช ุฎุจูุฑ ุชุณุนูุฑ ุนุทูุฑ. ูุฑูุฑ: โููุงูู / ๐ูุฎูุถ / ๐ดุฃุนูู / ๐๏ธุฅุฒุงูุฉ. ุฃุฌุจ ุจุงูุนุฑุจูุฉ.",
"general": """ุฃูุช ูุณุงุนุฏ ุฐูุงุก ุงุตุทูุงุนู ูุชุฎุตุต ูู ุชุณุนูุฑ ุงูุนุทูุฑ ุงููุงุฎุฑุฉ ูุงูุณูู ุงูุณุนูุฏู.
ุฎุจุฑุชู: ุชุญููู ุงูุฃุณุนุงุฑุ ุงูููุงูุณุฉุ ุงุณุชุฑุงุชูุฌูุงุช ุงูุชุณุนูุฑุ ููููุงุช ุงูุนุทูุฑ ููุฑุงูุฒ ุงูุฑุงุฆุญุฉ.
ุฃุฌุจ ุจุงูุนุฑุจูุฉ ุจุงุญุชุฑุงููุฉ ูุฅูุฌุงุฒ โ ููููู ุงุณุชุฎุฏุงู ุงูู markdown.""",
"verify": """ุฃูุช ุฎุจูุฑ ุชุญูู ูู ููุชุฌุงุช ุงูุนุทูุฑ.
ุฃุฌุจ JSON ููุท: {"match":true/false,"confidence":0-100,"reason":"","suggestion":"","market_price":0}""",
"market_search": """ุฃูุช ูุญูู ุฃุณุนุงุฑ ุนุทูุฑ (ุงูุณูู ุงูุณุนูุฏู).
ุฃุฌุจ JSON: {"market_price":0,"price_range":{"min":0,"max":0},"competitors":[{"name":"","price":0}],"recommendation":""}""",
}

# โโ ุงุณุชุฏุนุงุก Gemini โโโโโโโโโโโโโโโโโโโโโโโโโโ
def _call_gemini(prompt, system="", grounding=False, stream=False):
    full = f"{system}\n\n{prompt}" if system else prompt
    payload = {
        "contents": [{"parts": [{"text": full}]}],
        "generationConfig": {"temperature": 0.3, "maxOutputTokens": 4096, "topP": 0.85}
    }
    if grounding:
        payload["tools"] = [{"google_search": {}}]

    for key in GEMINI_API_KEYS:
        if not key: continue
        try:
            r = requests.post(f"{_GU}?key={key}", json=payload, timeout=35)
            if r.status_code == 200:
                data = r.json()
                if data.get("candidates"):
                    parts = data["candidates"][0]["content"]["parts"]
                    return "".join(p.get("text","") for p in parts)
            elif r.status_code == 429:
                time.sleep(1); continue
        except: continue
    return None

def _call_openrouter(prompt, system=""):
    if not OPENROUTER_API_KEY: return None
    try:
        msgs = []
        if system: msgs.append({"role":"system","content":system})
        msgs.append({"role":"user","content":prompt})
        r = requests.post(_OR, json={
            "model":"google/gemini-2.0-flash-001",
            "messages":msgs,"temperature":0.3,"max_tokens":4096
        }, headers={"Authorization":f"Bearer {OPENROUTER_API_KEY}"}, timeout=35)
        if r.status_code == 200:
            return r.json()["choices"][0]["message"]["content"]
    except: pass
    return None

def _call_cohere(prompt, system=""):
    if not COHERE_API_KEY: return None
    try:
        full = f"{system}\n\n{prompt}" if system else prompt
        r = requests.post(_CO, json={
            "model":"command-r-plus","prompt":full,"max_tokens":4096,"temperature":0.3
        }, headers={"Authorization":f"Bearer {COHERE_API_KEY}"}, timeout=35)
        if r.status_code == 200:
            return r.json().get("generations",[{}])[0].get("text","")
    except: pass
    return None

def call_ai(prompt, page="general"):
    sys = PAGE_PROMPTS.get(page, PAGE_PROMPTS["general"])
    for fn in [lambda: _call_gemini(prompt, sys),
               lambda: _call_openrouter(prompt, sys),
               lambda: _call_cohere(prompt, sys)]:
        r = fn()
        if r: return {"success":True,"response":r,"source":fn.__name__ if hasattr(fn,"__name__") else "AI"}
    # fallback source names
    for r, src in [(_call_gemini(prompt,sys),"Gemini"),
                   (_call_openrouter(prompt,sys),"OpenRouter"),
                   (_call_cohere(prompt,sys),"Cohere")]:
        if r: return {"success":True,"response":r,"source":src}
    return {"success":False,"response":"โ ูุดู ุงูุงุชุตุงู ุจุฌููุน ูุฒูุฏู AI","source":"none"}

# โโ Gemini Chat ูุน History โโโโโโโโโโโโโโโโโโ
def gemini_chat(message, history=None, system_extra=""):
    """ุฏุฑุฏุดุฉ Gemini ูุน ูุงูู ุชุงุฑูุฎ ุงููุญุงุฏุซุฉ"""
    sys = PAGE_PROMPTS["general"]
    if system_extra:
        sys = f"{sys}\n\nุณูุงู ุฅุถุงูู: {system_extra}"

    contents = []
    for h in (history or [])[-12:]:
        contents.append({"role":"user","parts":[{"text":h["user"]}]})
        contents.append({"role":"model","parts":[{"text":h["ai"]}]})
    contents.append({"role":"user","parts":[{"text":f"{sys}\n\n{message}"}]})

    payload = {"contents":contents,
               "generationConfig":{"temperature":0.4,"maxOutputTokens":4096,"topP":0.9}}

    for key in GEMINI_API_KEYS:
        if not key: continue
        try:
            r = requests.post(f"{_GU}?key={key}", json=payload, timeout=40)
            if r.status_code == 200:
                data = r.json()
                if data.get("candidates"):
                    text = data["candidates"][0]["content"]["parts"][0]["text"]
                    return {"success":True,"response":text,"source":"Gemini Flash"}
            elif r.status_code == 429:
                time.sleep(1); continue
        except: continue

    r = _call_openrouter(message, sys)
    if r: return {"success":True,"response":r,"source":"OpenRouter"}
    return {"success":False,"response":"โ ูุดู ุงูุงุชุตุงู","source":"none"}

# โโ ุชุญูู ููุชุฌ โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
def verify_match(p1, p2, pr1=0, pr2=0):
    prompt = f"""ุชุญูู ูู ุชุทุงุจู ูุฐูู ุงูููุชุฌูู:
ููุชุฌ 1: {p1} | ุงูุณุนุฑ: {pr1:.0f} ุฑ.ุณ
ููุชุฌ 2: {p2} | ุงูุณุนุฑ: {pr2:.0f} ุฑ.ุณ
ูู ููุง ููุณ ุงูุนุทุฑุ (ูุงุฑูุฉ + ุงุณู + ุญุฌู + ููุน EDP/EDT)"""
    sys = PAGE_PROMPTS["verify"]
    txt = _call_gemini(prompt, sys) or _call_openrouter(prompt, sys)
    if not txt: return {"success":False,"match":False,"confidence":0,"reason":"ูุดู AI"}
    try:
        clean = re.sub(r'```json|```','',txt).strip()
        s=clean.find('{'); e=clean.rfind('}')+1
        data = json.loads(clean[s:e])
        return {"success":True, **data}
    except:
        return {"success":True,"match":"true" in txt.lower(),"confidence":70,"reason":txt[:200]}

# โโ ุจุญุซ ุฃุณุนุงุฑ ุงูุณูู โโโโโโโโโโโโโโโโโโโโโโโโโ
def search_market_price(product_name, our_price=0):
    prompt = (f"ูุง ูู ุณุนุฑ ุงูุณูู ุงูุณุนูุฏู ุงูุญุงูู ูู: ยซ{product_name}ยปุ\n"
              f"ุณุนุฑูุง ุงูุญุงูู: {our_price:.0f} ุฑ.ุณ\n"
              "ุงุฐูุฑ: ุณุนุฑ ุงูุณููุ ูุทุงู ุงูุฃุณุนุงุฑุ ุฃูู 3 ููุงูุณูู ูุฃุณุนุงุฑููุ ุชูุตูุชู.")
    sys = PAGE_PROMPTS["market_search"]
    txt = _call_gemini(prompt, sys, grounding=True) or _call_gemini(prompt, sys) or _call_openrouter(prompt, sys)
    if not txt: return {"success":False,"market_price":0}
    try:
        clean = re.sub(r'```json|```','',txt).strip()
        s=clean.find('{'); e=clean.rfind('}')+1
        if s>=0 and e>s:
            return {"success":True, **json.loads(clean[s:e])}
    except: pass
    return {"success":True,"market_price":our_price,"recommendation":txt[:300]}

# โโ ุจุญุซ ุตูุฑุฉ ูููููุงุช ูู Fragrantica Arabia โโ
def fetch_fragrantica_info(product_name):
    """
    ูุจุญุซ ุนู ุตูุฑุฉ + ููููุงุช ุงูุนุทุฑ ูู Fragrantica Arabia
    ูุณุชุฎุฏู Gemini Grounding ูููุตูู ูููููุน
    """
    prompt = f"""ุงุจุญุซ ุนู ุงูุนุทุฑ ยซ{product_name}ยป ูู ูููุน https://www.fragranticarabia.com

ุฃุญุชุงุฌ:
1. ุฑุงุจุท ุตูุฑุฉ ุงูููุชุฌ (image URL)
2. ููููุงุช ุงูุนุทุฑ (Top notes, Middle notes, Base notes)
3. ูุตู ูุตูุฑ ููุนุทุฑ ุจุงูุนุฑุจูุฉ
4. ุงููุงุฑูุฉ ูุงูููุน (EDP/EDT) ูุงูุญุฌู

ุฃุฌุจ JSON ููุท:
{{
  "image_url": "ุฑุงุจุท ุงูุตูุฑุฉ ุฃู ูุงุฑุบ",
  "top_notes": ["ูููู1","ูููู2"],
  "middle_notes": ["ูููู1","ูููู2"],
  "base_notes": ["ูููู1","ูููู2"],
  "description_ar": "ูุตู ูุตูุฑ ุจุงูุนุฑุจูุฉ",
  "brand": "",
  "type": "",
  "fragrantica_url": "ุฑุงุจุท ุงูุตูุญุฉ"
}}"""

    txt = _call_gemini(prompt, grounding=True)
    if not txt:
        txt = _call_gemini(prompt)
    if not txt:
        return {"success":False}
    try:
        clean = re.sub(r'```json|```','',txt).strip()
        s=clean.find('{'); e=clean.rfind('}')+1
        if s>=0 and e>s:
            data = json.loads(clean[s:e])
            return {"success":True, **data}
    except: pass
    return {"success":False,"description_ar":txt[:200] if txt else ""}

# โโ ูุตู ููููุณ ููููุชุฌุงุช ุงูููููุฏุฉ โโโโโโโโโโโโ
def generate_mahwous_description(product_name, price, fragrantica_data=None):
    """
    ููููุฏ ูุตูุงู ุจุชูุณูู ููููุณ ุงูุงุญุชุฑุงูู:
    ุงุณู ุงูุนุทุฑุ ุงููุงุฑูุฉุ ุงูููููุงุชุ ุงููุตู ุงูุดุนุฑูุ ุงูุณุนุฑ ุงูููุชุฑุญ
    """
    frag_info = ""
    if fragrantica_data and fragrantica_data.get("success"):
        top = ", ".join(fragrantica_data.get("top_notes",[])[:4])
        mid = ", ".join(fragrantica_data.get("middle_notes",[])[:4])
        base = ", ".join(fragrantica_data.get("base_notes",[])[:4])
        desc = fragrantica_data.get("description_ar","")
        frag_info = f"\nุงูููููุงุช - ููุฉ: {top} | ููุจ: {mid} | ูุงุนุฏุฉ: {base}\nูุตู: {desc}"

    prompt = f"""ุงูุชุจ ูุตูุงู ุงุญุชุฑุงููุงู ูุฌุฐุงุจุงู ููุฐุง ุงูุนุทุฑ ุจุชูุณูู ูุชุฌุฑ ููููุณ:

ุงูุนุทุฑ: {product_name}
ุงูุณุนุฑ: {price:.0f} ุฑ.ุณ{frag_info}

ุงูุชูุณูู ุงููุทููุจ (ุงุชุจุนู ุจุฏูุฉ):
---
๐ [ุงุณู ุงูุนุทุฑ ุงููุงูู]

โจ [ุฌููุฉ ุชุณููููุฉ ุฌุฐุงุจุฉ ุจุงูุนุฑุจูุฉ - ุณุทุฑ ูุงุญุฏ]

๐ [ููุฑุฉ ูุตู ุดุนุฑู 2-3 ุฌูู ุชุตู ุฑุงุฆุญุฉ ุงูุนุทุฑ ูุฃุฌูุงุกู]

๐ธ ููููุงุช ุงูุนุทุฑ:
โข ุงูููุฉ: [ุงูููููุงุช]
โข ุงูููุจ: [ุงูููููุงุช]
โข ุงููุงุนุฏุฉ: [ุงูููููุงุช]

๐ค ููุงุณุจ ูู: [ุงูุฌูุณ] | ๐ ุงูููุงุณุจุฉ: [ุงูููุงุฑ/ุงููุณุงุก/ุงููุฎุชูุทุฉ]

๐ฐ ุงูุณุนุฑ: {price:.0f} ุฑ.ุณ
---
ุฃุฌุจ ุจุงูุนุฑุจูุฉ ููุท."""

    txt = _call_gemini(prompt) or _call_openrouter(prompt) or _call_cohere(prompt)
    return txt or f"๐ {product_name}\n๐ฐ ุงูุณุนุฑ: {price:.0f} ุฑ.ุณ"

# โโ ุจุญุซ mahwous.com โโโโโโโโโโโโโโโโโโโโโโโโโโ
def search_mahwous(product_name):
    prompt = f"""ูู ุงูุนุทุฑ ยซ{product_name}ยป ูุชููุฑ ูู ูุชุฌุฑ ููููุณุ
ุฃุฌุจ JSON: {{"likely_available":true/false,"confidence":0-100,
"similar_products":[],"add_recommendation":"ุนุงููุฉ/ูุชูุณุทุฉ/ููุฎูุถุฉ",
"reason":"ุณุจุจ ูุฎุชุตุฑ","suggested_price":0}}"""
    txt = _call_gemini(prompt, grounding=True) or _call_gemini(prompt)
    if not txt: return {"success":False}
    try:
        clean = re.sub(r'```json|```','',txt).strip()
        s=clean.find('{'); e=clean.rfind('}')+1
        if s>=0 and e>s:
            return {"success":True, **json.loads(clean[s:e])}
    except: pass
    return {"success":True,"likely_available":False,"confidence":50,"reason":txt[:150]}

# โโ ุชุญูู ููุฑุฑ โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
def check_duplicate(product_name, our_products):
    if not our_products:
        return {"success":True,"response":"ูุง ุชูุฌุฏ ุจูุงูุงุช ููููุงุฑูุฉ"}
    sample = our_products[:30]
    prompt = f"""ูู ุงูุนุทุฑ ยซ{product_name}ยป ููุฌูุฏ ุจุดูู ูุดุงุจู ูู ูุฐู ุงููุงุฆูุฉุ
ุงููุงุฆูุฉ: {', '.join(str(p) for p in sample)}
ุฃุฌุจ: ูุนู (ูุฐูุฑ ุฃูุฑุจ ูุทุงุจูุฉ) ุฃู ูุง."""
    r = call_ai(prompt, "missing")
    return r

# โโ ุชุญููู ูุฌูุน โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
def bulk_verify(items, section="general"):
    if not items: return {"success":False,"response":"ูุง ุชูุฌุฏ ููุชุฌุงุช"}
    lines = "\n".join(
        f"{i+1}. {it.get('our','')} โ {it.get('comp','')} | "
        f"ุณุนุฑูุง: {it.get('our_price',0):.0f} | ููุงูุณ: {it.get('comp_price',0):.0f} | "
        f"ูุฑู: {it.get('our_price',0)-it.get('comp_price',0):+.0f}"
        for i,it in enumerate(items)
    )
    prompt = f"ุญููู ูุฐู ุงูููุชุฌุงุช ูุฃุนุทู ุชูุตูุฉ ููู ูููุง:\n{lines}"
    return call_ai(prompt, section)

# โโ ูุนุงูุฌุฉ ุงููุต ุงูููุตูู โโโโโโโโโโโโโโโโโโโโโ
def analyze_paste(text, context=""):
    """ุชุญููู ูุต ููุตูู ูู Excel ุฃู ุฃู ูุตุฏุฑ"""
    prompt = f"""ุงููุณุชุฎุฏู ูุตู ูุฐุง ุงููุต:{chr(10) + context if context else ''}

---
{text[:5000]}
---

ุญููู ูุฐุง ุงููุต ูุงุณุชุฎุฑุฌ:
1. ูู ูู ูุงุฆูุฉ ููุชุฌุงุชุ ุฅุฐุง ูุนูุ ุงุนุฑุถูุง ุจุดูู ููุธู
2. ุฅุฐุง ูุงูุช ุฃุณุนุงุฑุ ุญูููุง ููุงุฑููุง
3. ุฅุฐุง ูุงูุช ุฃูุงูุฑุ ููุฐูุง ูุฃุฎุจุฑ ุจุงููุชูุฌุฉ
4. ุฃุนุทู ุชูุตูุงุช ูููุฏุฉ ุจูุงุกู ุนูู ุงูุจูุงูุงุช
ุฃุฌุจ ุจุงูุนุฑุจูุฉ ุจุดูู ููุธู."""
    return call_ai(prompt, "general")

# โโ ุฏูุงู ูุชูุงููุฉ ูุน app.py ุงููุฏูู โโโโโโโโโโ
def chat_with_ai(msg, history=None, ctx=""): return gemini_chat(msg, history, ctx)
def analyze_product(p, price=0): return call_ai(f"ุญููู: {p} ({price:.0f}ุฑ.ุณ)", "general")
def suggest_price(p, comp_price): return call_ai(f"ุงูุชุฑุญ ุณุนุฑุงู ูู {p} ุจุฏูุงู ูู {comp_price:.0f}ุฑ.ุณ", "general")
def process_paste(text): return analyze_paste(text)
